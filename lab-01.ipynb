{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fd487d21",
   "metadata": {},
   "source": [
    "# Lab 01 - Data exploration and preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fbc1481d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import dependencies\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c858f34",
   "metadata": {},
   "source": [
    "## Introduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85ba1545",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "93e36221",
   "metadata": {},
   "source": [
    "### Dataset description\n",
    "\n",
    "The sinking of the Titanic is one of the most infamous shipwrecks in history.\n",
    "\n",
    "On April 15, 1912, during her maiden voyage, the widely considered “unsinkable” RMS Titanic sank after colliding with an iceberg. Unfortunately, there weren’t enough lifeboats for everyone onboard, resulting in the death of 1502 out of 2224 passengers and crew.\n",
    "\n",
    "While there was some element of luck involved in surviving, it seems some groups of people were more likely to survive than others.\n",
    "\n",
    "In this challenge, we ask you to build a predictive model that answers the question: “what sorts of people were more likely to survive?” using passenger data (ie name, age, gender, socio-economic class, etc).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7071aecd",
   "metadata": {},
   "source": [
    "| Column Name | Data Type | Description | Possible Values |\n",
    "|-------------|-----------|-------------|----------------|\n",
    "| PassengerId | Integer   | Unique identifier for each passenger | 1, 2, 3, etc. |\n",
    "| Survived    | Integer   | Survival indicator | 0 = No (Did not survive), 1 = Yes (Survived) |\n",
    "| Pclass      | Integer   | Passenger ticket class | 1 = 1st/Upper, 2 = 2nd/Middle, 3 = 3rd/Lower |\n",
    "| Name        | String    | Full name of the passenger | \"Braund, Mr. Owen Harris\", etc. |\n",
    "| Sex         | String    | Gender of the passenger | \"male\", \"female\" |\n",
    "| Age         | Float     | Age of the passenger in years | 22.0, 40.0, etc. (may contain missing values) |\n",
    "| SibSp       | Integer   | Number of siblings/spouses aboard the Titanic | 0, 1, 2, etc. |\n",
    "| Parch       | Integer   | Number of parents/children aboard the Titanic | 0, 1, 2, etc. |\n",
    "| Ticket      | String    | Ticket number | \"A/5 21171\", \"PC 17599\", etc. |\n",
    "| Fare        | Float     | Price paid for the ticket | 7.25, 71.2833, etc. |\n",
    "| Cabin       | String    | Cabin number | \"C85\", \"E46\", etc. (many missing values) |\n",
    "| Embarked    | String    | Port of embarkation | \"C\" = Cherbourg, \"Q\" = Queenstown, \"S\" = Southampton |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5866566",
   "metadata": {},
   "source": [
    "### Objective of the lab\n",
    "\n",
    "The quality of the data and the amount of useful information that it contains are key factors that determine how well a machine learning algorithm can learn. Therefore, it is absolutely critical that we make sure to examine and preprocess a dataset before we feed it to a learning algorithm. \n",
    "\n",
    "In this laboratory we will explore the data exploration and preprocessing pipeline."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2938e958",
   "metadata": {},
   "source": [
    "#### What is a Dataset?\n",
    "\n",
    "A data set (or dataset) is a collection of data. In the case of tabular data, a data set corresponds to one or more database tables, where every **column** of a table represents a particular **variable**, and each **row** corresponds to a given **record of the data** set in question. The data set lists values for each of the variables, such as for example height and weight of an object, for each member of the data set. Data sets can also consist of a collection of documents or files\n",
    "\n",
    "Several characteristics define a data set's structure and properties. These include the number and types of the attributes or variables, and various statistical measures applicable to them.\n",
    "\n",
    "The values may be numbers, such as real numbers or integers, for example representing a person's height in centimeters, but may also be nominal data (i.e., not consisting of numerical values), for example representing a person's ethnicity. More generally, values may be of any of the kinds described as a level of measurement.\n",
    "\n",
    "Missing values may exist, which must be indicated somehow.\n",
    "\n",
    "[Data set - Wikipedia](https://en.wikipedia.org/wiki/Data_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bad7a3aa",
   "metadata": {},
   "source": [
    "#### What are the different types of data?\n",
    "\n",
    "The two main types of data are:\n",
    "\n",
    "- Qualitative Data\n",
    "- Quantitative Data\n",
    "\n",
    "![types-of-data-img](img\\types-of-data-1024x555-1.png)\n",
    "\n",
    "---\n",
    "\n",
    "**Qualitative or Categorical Data**\n",
    "   \n",
    "Qualitative or Categorical Data is a type of data that can’t be measured or counted in the form of numbers. These types of data are sorted by category, not by number. That’s why it is also known as Categorical Data. \n",
    "\n",
    "These data consist of audio, images, symbols, or text. The gender of a person, i.e., male, female, or others, is qualitative data.\n",
    "\n",
    "Qualitative data tells about the perception of people. This data helps market researchers understand the customers’ tastes and then design their ideas and strategies accordingly. \n",
    "\n",
    "The Qualitative data are further classified into two parts :\n",
    "   \n",
    "- Nominal Data\n",
    "    Nominal Data is used to label variables without any order or quantitative value. The color of hair can be considered nominal data, as one color can’t be compared with another color.\n",
    "\n",
    "    With the help of nominal data, we can’t do any numerical tasks or can’t give any order to sort the data. These data don’t have any meaningful order; their values are distributed into distinct categories.\n",
    "\n",
    "- Ordinal Data\n",
    "\n",
    "    Ordinal data have natural ordering where a number is present in some kind of order by their position on the scale. These data are used for observation like customer satisfaction, happiness, etc., but we can’t do any arithmetical tasks on them. \n",
    "\n",
    "    Ordinal data is qualitative data for which their values have some kind of relative position. These kinds of data can be considered “in-between” qualitative and quantitative data.\n",
    "\n",
    "    The ordinal data only shows the sequences and cannot use for statistical analysis. Compared to nominal data, ordinal data have some kind of order that is not present in nominal data. \n",
    "\n",
    "--- \n",
    "\n",
    "**Quantitative Data**\n",
    "   \n",
    "Quantitative data is a type of data that can be expressed in numerical values, making it countable and including statistical data analysis. These kinds of data are also known as Numerical data.\n",
    "\n",
    "It answers the questions like “how much,” “how many,” and “how often.” For example, the price of a phone, the computer’s ram, the height or weight of a person, etc., falls under quantitative data. \n",
    "\n",
    "Quantitative data can be used for statistical manipulation. These data can be represented on a wide variety of graphs and charts, such as bar graphs, histograms, scatter plots, boxplots, pie charts, line graphs, etc.\n",
    "\n",
    "- Discrete Data\n",
    "\n",
    "    The term discrete means distinct or separate. The discrete data contain the values that fall under integers or whole numbers. The total number of students in a class is an example of discrete data. These data can’t be broken into decimal or fraction values.\n",
    "\n",
    "    The discrete data are countable and have finite values; their subdivision is not possible. These data are represented mainly by a bar graph, number line, or frequency table.\n",
    "\n",
    "- Continuous Data\n",
    "\n",
    "    Continuous data are in the form of fractional numbers. It can be the version of an android phone, the height of a person, the length of an object, etc. Continuous data represents information that can be divided into smaller levels. The continuous variable can take any value within a range. \n",
    "\n",
    "    The key difference between discrete and continuous data is that discrete data contains the integer or whole number. Still, continuous data stores the fractional numbers to record different types of data such as temperature, height, width, time, speed, etc.\n",
    "\n",
    "[Types Of Data - Great Learning](https://www.mygreatlearning.com/blog/types-of-data/)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b35bcc3",
   "metadata": {},
   "source": [
    "## Dataset Loading\n",
    "\n",
    "To start working with any dataset in Python, we typically use the pandas library, which allows us to load, manipulate, and analyze data easily in tabular form.\n",
    "\n",
    "In this case, the Titanic dataset is available in a CSV file. We'll load it using pandas.read_csv().\n",
    "\n",
    "For loading file we need Pandas library.\n",
    "\n",
    "What is Pandas? \n",
    "\n",
    "Pandas is one of the most important and widely-used Python libraries in data science, data analysis, and machine learning.\n",
    "\n",
    "It was created specifically to make working with structured data (like tables and spreadsheets) fast, flexible, and expressive.\n",
    "\n",
    "The name \"pandas\" is derived from \"Panel Data\", which is an econometrics term for multidimensional structured data, and also a fun nod to the panda bear 🐼."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8c070b48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pandas\n",
      "  Downloading pandas-2.2.3-cp313-cp313-win_amd64.whl.metadata (19 kB)\n",
      "Collecting numpy>=1.26.0 (from pandas)\n",
      "  Downloading numpy-2.2.4-cp313-cp313-win_amd64.whl.metadata (60 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\pc1\\appdata\\roaming\\python\\python313\\site-packages (from pandas) (2.9.0.post0)\n",
      "Collecting pytz>=2020.1 (from pandas)\n",
      "  Downloading pytz-2025.2-py2.py3-none-any.whl.metadata (22 kB)\n",
      "Collecting tzdata>=2022.7 (from pandas)\n",
      "  Downloading tzdata-2025.2-py2.py3-none-any.whl.metadata (1.4 kB)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\pc1\\appdata\\roaming\\python\\python313\\site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Downloading pandas-2.2.3-cp313-cp313-win_amd64.whl (11.5 MB)\n",
      "   ---------------------------------------- 0.0/11.5 MB ? eta -:--:--\n",
      "   --- ------------------------------------ 1.0/11.5 MB 5.6 MB/s eta 0:00:02\n",
      "   ------- -------------------------------- 2.1/11.5 MB 5.6 MB/s eta 0:00:02\n",
      "   ----------- ---------------------------- 3.4/11.5 MB 5.7 MB/s eta 0:00:02\n",
      "   --------------- ------------------------ 4.5/11.5 MB 5.4 MB/s eta 0:00:02\n",
      "   ----------------- ---------------------- 5.0/11.5 MB 5.2 MB/s eta 0:00:02\n",
      "   -------------------- ------------------- 5.8/11.5 MB 4.6 MB/s eta 0:00:02\n",
      "   ---------------------- ----------------- 6.6/11.5 MB 4.5 MB/s eta 0:00:02\n",
      "   ------------------------- -------------- 7.3/11.5 MB 4.3 MB/s eta 0:00:01\n",
      "   ----------------------------- ---------- 8.4/11.5 MB 4.4 MB/s eta 0:00:01\n",
      "   ------------------------------ --------- 8.7/11.5 MB 4.4 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 9.4/11.5 MB 4.0 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 10.0/11.5 MB 4.0 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 11.0/11.5 MB 4.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------  11.3/11.5 MB 3.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 11.5/11.5 MB 3.6 MB/s eta 0:00:00\n",
      "Downloading numpy-2.2.4-cp313-cp313-win_amd64.whl (12.6 MB)\n",
      "   ---------------------------------------- 0.0/12.6 MB ? eta -:--:--\n",
      "   -- ------------------------------------- 0.8/12.6 MB 3.6 MB/s eta 0:00:04\n",
      "   --- ------------------------------------ 1.0/12.6 MB 2.4 MB/s eta 0:00:05\n",
      "   ------ --------------------------------- 2.1/12.6 MB 3.2 MB/s eta 0:00:04\n",
      "   ---------- ----------------------------- 3.4/12.6 MB 4.0 MB/s eta 0:00:03\n",
      "   ------------- -------------------------- 4.2/12.6 MB 4.2 MB/s eta 0:00:02\n",
      "   --------------- ------------------------ 5.0/12.6 MB 3.9 MB/s eta 0:00:02\n",
      "   ---------------- ----------------------- 5.2/12.6 MB 3.9 MB/s eta 0:00:02\n",
      "   ------------------- -------------------- 6.0/12.6 MB 3.5 MB/s eta 0:00:02\n",
      "   ------------------- -------------------- 6.3/12.6 MB 3.3 MB/s eta 0:00:02\n",
      "   --------------------- ------------------ 6.8/12.6 MB 3.1 MB/s eta 0:00:02\n",
      "   ----------------------- ---------------- 7.3/12.6 MB 3.1 MB/s eta 0:00:02\n",
      "   ------------------------ --------------- 7.9/12.6 MB 3.0 MB/s eta 0:00:02\n",
      "   --------------------------- ------------ 8.7/12.6 MB 3.2 MB/s eta 0:00:02\n",
      "   ------------------------------ --------- 9.7/12.6 MB 3.2 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 10.2/12.6 MB 3.2 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 11.0/12.6 MB 3.2 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 11.8/12.6 MB 3.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------  12.6/12.6 MB 3.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 12.6/12.6 MB 3.1 MB/s eta 0:00:00\n",
      "Downloading pytz-2025.2-py2.py3-none-any.whl (509 kB)\n",
      "Downloading tzdata-2025.2-py2.py3-none-any.whl (347 kB)\n",
      "Installing collected packages: pytz, tzdata, numpy, pandas\n",
      "Successfully installed numpy-2.2.4 pandas-2.2.3 pytz-2025.2 tzdata-2025.2\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  WARNING: The scripts f2py.exe and numpy-config.exe are installed in 'c:\\Users\\PC1\\AppData\\Local\\Programs\\Python\\Python313\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "\n",
      "[notice] A new release of pip is available: 24.2 -> 25.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "54d1bc21",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  \\\n",
       "0            1         0       3   \n",
       "1            2         1       1   \n",
       "2            3         1       3   \n",
       "3            4         1       1   \n",
       "4            5         0       3   \n",
       "\n",
       "                                                Name     Sex   Age  SibSp  \\\n",
       "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
       "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
       "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
       "4                           Allen, Mr. William Henry    male  35.0      0   \n",
       "\n",
       "   Parch            Ticket     Fare Cabin Embarked  \n",
       "0      0         A/5 21171   7.2500   NaN        S  \n",
       "1      0          PC 17599  71.2833   C85        C  \n",
       "2      0  STON/O2. 3101282   7.9250   NaN        S  \n",
       "3      0            113803  53.1000  C123        S  \n",
       "4      0            373450   8.0500   NaN        S  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the dataset from the subfolder 'data/lab-01'\n",
    "df = pd.read_csv('data/lab-01/Titanic-Dataset.csv')\n",
    "\n",
    "# Display the first 5 rows to check it's loaded correctly\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4b7cb1f",
   "metadata": {},
   "source": [
    "## Dataset Overview\n",
    "\n",
    "\n",
    "Now that we’ve successfully loaded the dataset, it’s time to explore and play with it.\n",
    "\n",
    "Before we start building any machine learning models or visualizations, we must understand:\n",
    "\n",
    "- What kind of data we are working with\n",
    "\n",
    "- The distribution of values across key columns\n",
    "\n",
    "- If there are any unusual or suspicious entries (outliers, wrong types, etc.)\n",
    "\n",
    "This step is known as Exploratory Data Analysis (EDA) — and it’s one of the most important steps in any data science project.\n",
    "\n",
    "🔍 Why Is This Step Important?\n",
    "\n",
    "- ✅ Data Understanding: We need to understand what each column means, what type of values it contains, and how it could relate to the outcome we want to predict (in this case, survival).\n",
    "\n",
    "- 🚩 Anomaly Detection: This helps us spot outliers, inconsistent data, or wrong data types — all of which can affect the performance of our models.\n",
    "\n",
    "- 🛠️ Planning Data Cleaning: Based on this step, we can make decisions about missing values, column drops, or transformations needed later.\n",
    "\n",
    "This step is called Exploratory Data Analysis (EDA), and it’s one of the most critical stages in any data science pipeline.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7a24cc6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset shape: (891, 12)\n",
      "\n",
      "Column names:\n",
      " ['PassengerId', 'Survived', 'Pclass', 'Name', 'Sex', 'Age', 'SibSp', 'Parch', 'Ticket', 'Fare', 'Cabin', 'Embarked']\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 891 entries, 0 to 890\n",
      "Data columns (total 12 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   PassengerId  891 non-null    int64  \n",
      " 1   Survived     891 non-null    int64  \n",
      " 2   Pclass       891 non-null    int64  \n",
      " 3   Name         891 non-null    object \n",
      " 4   Sex          891 non-null    object \n",
      " 5   Age          714 non-null    float64\n",
      " 6   SibSp        891 non-null    int64  \n",
      " 7   Parch        891 non-null    int64  \n",
      " 8   Ticket       891 non-null    object \n",
      " 9   Fare         891 non-null    float64\n",
      " 10  Cabin        204 non-null    object \n",
      " 11  Embarked     889 non-null    object \n",
      "dtypes: float64(2), int64(5), object(5)\n",
      "memory usage: 83.7+ KB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>714.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>446.000000</td>\n",
       "      <td>0.383838</td>\n",
       "      <td>2.308642</td>\n",
       "      <td>29.699118</td>\n",
       "      <td>0.523008</td>\n",
       "      <td>0.381594</td>\n",
       "      <td>32.204208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>257.353842</td>\n",
       "      <td>0.486592</td>\n",
       "      <td>0.836071</td>\n",
       "      <td>14.526497</td>\n",
       "      <td>1.102743</td>\n",
       "      <td>0.806057</td>\n",
       "      <td>49.693429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.420000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>223.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>20.125000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.910400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>446.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>28.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>14.454200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>668.500000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>38.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>31.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>891.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>512.329200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       PassengerId    Survived      Pclass         Age       SibSp  \\\n",
       "count   891.000000  891.000000  891.000000  714.000000  891.000000   \n",
       "mean    446.000000    0.383838    2.308642   29.699118    0.523008   \n",
       "std     257.353842    0.486592    0.836071   14.526497    1.102743   \n",
       "min       1.000000    0.000000    1.000000    0.420000    0.000000   \n",
       "25%     223.500000    0.000000    2.000000   20.125000    0.000000   \n",
       "50%     446.000000    0.000000    3.000000   28.000000    0.000000   \n",
       "75%     668.500000    1.000000    3.000000   38.000000    1.000000   \n",
       "max     891.000000    1.000000    3.000000   80.000000    8.000000   \n",
       "\n",
       "            Parch        Fare  \n",
       "count  891.000000  891.000000  \n",
       "mean     0.381594   32.204208  \n",
       "std      0.806057   49.693429  \n",
       "min      0.000000    0.000000  \n",
       "25%      0.000000    7.910400  \n",
       "50%      0.000000   14.454200  \n",
       "75%      0.000000   31.000000  \n",
       "max      6.000000  512.329200  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the shape of the dataset (rows, columns)\n",
    "print(\"Dataset shape:\", df.shape)\n",
    "\n",
    "# Show the column names\n",
    "print(\"\\nColumn names:\\n\", df.columns.tolist())\n",
    "\n",
    "# Display information about each column (data type, non-null values, etc.)\n",
    "df.info()\n",
    "\n",
    "# Summary statistics for numerical columns\n",
    "df.describe()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d54d8a85",
   "metadata": {},
   "source": [
    "## Data Quality Check\n",
    "\n",
    "Before we analyze or build models with our dataset, we need to ensure that the data is clean, complete, and reliable.\n",
    "\n",
    "Even in well-known datasets like the Titanic dataset, we might encounter:\n",
    "\n",
    "- ❌ Missing values: Empty cells or NaNs that need to be filled, removed, or flagged.\n",
    "\n",
    "- 🧩 Inconsistent or incorrect formats: For example, a numerical column with text entries.\n",
    "\n",
    "- 🎭 Duplicated entries: Repeated rows that can skew statistics and model results.\n",
    "\n",
    "- 🧱 Outliers or unrealistic values: Extremely high or low numbers that don’t make sense (e.g., negative ages).\n",
    "\n",
    "These issues can significantly affect model accuracy and lead to false conclusions. So, this step focuses on detecting potential problems and planning how to handle them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "763f5a1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🚫 Missing values per column:\n",
      "PassengerId      0\n",
      "Survived         0\n",
      "Pclass           0\n",
      "Name             0\n",
      "Sex              0\n",
      "Age            177\n",
      "SibSp            0\n",
      "Parch            0\n",
      "Ticket           0\n",
      "Fare             0\n",
      "Cabin          687\n",
      "Embarked         2\n",
      "dtype: int64\n",
      "\n",
      "📊 Percentage of missing values:\n",
      "PassengerId     0.000000\n",
      "Survived        0.000000\n",
      "Pclass          0.000000\n",
      "Name            0.000000\n",
      "Sex             0.000000\n",
      "Age            19.865320\n",
      "SibSp           0.000000\n",
      "Parch           0.000000\n",
      "Ticket          0.000000\n",
      "Fare            0.000000\n",
      "Cabin          77.104377\n",
      "Embarked        0.224467\n",
      "dtype: float64\n",
      "\n",
      "📋 Number of duplicated rows:\n",
      "0\n",
      "\n",
      "🔍 Rows with missing 'Age':\n",
      "    PassengerId  Survived  Pclass                           Name     Sex  Age  \\\n",
      "5             6         0       3               Moran, Mr. James    male  NaN   \n",
      "17           18         1       2   Williams, Mr. Charles Eugene    male  NaN   \n",
      "19           20         1       3        Masselmani, Mrs. Fatima  female  NaN   \n",
      "26           27         0       3        Emir, Mr. Farred Chehab    male  NaN   \n",
      "28           29         1       3  O'Dwyer, Miss. Ellen \"Nellie\"  female  NaN   \n",
      "\n",
      "    SibSp  Parch  Ticket     Fare Cabin Embarked  \n",
      "5       0      0  330877   8.4583   NaN        Q  \n",
      "17      0      0  244373  13.0000   NaN        S  \n",
      "19      0      0    2649   7.2250   NaN        C  \n",
      "26      0      0    2631   7.2250   NaN        C  \n",
      "28      0      0  330959   7.8792   NaN        Q  \n",
      "\n",
      "⚠️ Rows with invalid 'Age' values (if any):\n",
      "Empty DataFrame\n",
      "Columns: [PassengerId, Survived, Pclass, Name, Sex, Age, SibSp, Parch, Ticket, Fare, Cabin, Embarked]\n",
      "Index: []\n",
      "\n",
      "👀 Unique values in 'Sex' column:\n",
      "['male' 'female']\n"
     ]
    }
   ],
   "source": [
    "# 1. Check for missing values per column\n",
    "print(\"🚫 Missing values per column:\")\n",
    "print(df.isnull().sum())\n",
    "\n",
    "# 2. Optional: Check the percentage of missing values\n",
    "print(\"\\n📊 Percentage of missing values:\")\n",
    "print((df.isnull().sum() / len(df)) * 100)\n",
    "\n",
    "# 3. Check for duplicated rows\n",
    "print(\"\\n📋 Number of duplicated rows:\")\n",
    "print(df.duplicated().sum())\n",
    "\n",
    "# 4. Display rows with invalid or inconsistent data (examples)\n",
    "\n",
    "# Example: Show rows with missing 'Age'\n",
    "print(\"\\n🔍 Rows with missing 'Age':\")\n",
    "print(df[df['Age'].isnull()].head())\n",
    "\n",
    "# Example: Check for invalid ages (e.g., negative values)\n",
    "print(\"\\n⚠️ Rows with invalid 'Age' values (if any):\")\n",
    "print(df[df['Age'] < 0])\n",
    "\n",
    "# Example: Check for unknown 'Sex' values\n",
    "print(\"\\n👀 Unique values in 'Sex' column:\")\n",
    "print(df['Sex'].unique())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a86fdb7",
   "metadata": {},
   "source": [
    "## Descriptive Statistics\n",
    "\n",
    "After we’ve performed a basic overview and quality check, it’s time to understand how the values in our dataset are distributed — both numerical and categorical.\n",
    "\n",
    "This step is essential because:\n",
    "\n",
    "- It gives us an idea of the central tendency (e.g., average) and spread (e.g., variability) of data.\n",
    "\n",
    "- It reveals outliers, data imbalance, and patterns that may not be immediately obvious.\n",
    "\n",
    "- It helps us decide how to normalize, transform, or encode data before building models."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da3dba6c",
   "metadata": {},
   "source": [
    "## Basic Data Visualization\n",
    "\n",
    "After summarizing the dataset using statistics, the next step is to visualize the data. Visualization helps us spot patterns, trends, and anomalies that are hard to detect in raw numbers alone.\n",
    "\n",
    "These visual tools make data intuitive and accessible, even for those without strong statistical backgrounds.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc8d8eb3",
   "metadata": {},
   "source": [
    "📊 1. Histogram + KDE\n",
    "\n",
    "Purpose: Shows how a numerical variable is distributed (e.g., Age).\n",
    "\n",
    "- Histogram shows count of values in intervals\n",
    "\n",
    "- KDE (Kernel Density Estimation) smooths the distribution line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a6dffd6a",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (370712082.py, line 1)",
     "output_type": "error",
     "traceback": [
      "  \u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[11]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[31m    \u001b[39m\u001b[31mpip install matplotlib\u001b[39m\n        ^\n\u001b[31mSyntaxError\u001b[39m\u001b[31m:\u001b[39m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "pip install matplotlib\n",
    "pip install seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ee827da3",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'seaborn'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[8]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mseaborn\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msns\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mmatplotlib\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpyplot\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mplt\u001b[39;00m\n\u001b[32m      4\u001b[39m \u001b[38;5;66;03m# Histogram + KDE for Age\u001b[39;00m\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'seaborn'"
     ]
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Histogram + KDE for Age\n",
    "plt.figure(figsize=(8, 5))\n",
    "sns.histplot(data=df, x='Age', kde=True, bins=30)\n",
    "plt.title('Distribution of Age with KDE')\n",
    "plt.xlabel('Age')\n",
    "plt.ylabel('Frequency')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ca955e1",
   "metadata": {},
   "source": [
    "📦 2. Boxplot\n",
    "\n",
    "Purpose: Great for comparing numeric distributions across categories and spotting outliers.\n",
    "\n",
    "- Example: Age distribution by survival status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5c605b8c",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'plt' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[12]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Boxplot: Age vs. Survived\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m \u001b[43mplt\u001b[49m.figure(figsize=(\u001b[32m8\u001b[39m, \u001b[32m5\u001b[39m))\n\u001b[32m      3\u001b[39m sns.boxplot(data=df, x=\u001b[33m'\u001b[39m\u001b[33mSurvived\u001b[39m\u001b[33m'\u001b[39m, y=\u001b[33m'\u001b[39m\u001b[33mAge\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m      4\u001b[39m plt.title(\u001b[33m'\u001b[39m\u001b[33mBoxplot of Age by Survival\u001b[39m\u001b[33m'\u001b[39m)\n",
      "\u001b[31mNameError\u001b[39m: name 'plt' is not defined"
     ]
    }
   ],
   "source": [
    "# Boxplot: Age vs. Survived\n",
    "plt.figure(figsize=(8, 5))\n",
    "sns.boxplot(data=df, x='Survived', y='Age')\n",
    "plt.title('Boxplot of Age by Survival')\n",
    "plt.xlabel('Survived (0 = No, 1 = Yes)')\n",
    "plt.ylabel('Age')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23a6352c",
   "metadata": {},
   "source": [
    "📊 3. Count Plot (Bar Plot for Categories)\n",
    "\n",
    "Purpose: Displays the frequency of each category in a variable (like value_counts, but visual)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69ca462b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count plot: Sex\n",
    "plt.figure(figsize=(6, 4))\n",
    "sns.countplot(data=df, x='Sex')\n",
    "plt.title('Passenger Count by Sex')\n",
    "plt.xlabel('Sex')\n",
    "plt.ylabel('Count')\n",
    "plt.show()\n",
    "\n",
    "# Count plot: Pclass\n",
    "plt.figure(figsize=(6, 4))\n",
    "sns.countplot(data=df, x='Pclass')\n",
    "plt.title('Passenger Count by Class')\n",
    "plt.xlabel('Passenger Class')\n",
    "plt.ylabel('Count')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d7b8d4b",
   "metadata": {},
   "source": [
    "🌡️ 4. Correlation Heatmap\n",
    "\n",
    "Purpose: Helps you find numeric features that are positively or negatively correlated.\n",
    "\n",
    "- Values close to +1 → strong positive correlation\n",
    "\n",
    "- Values close to -1 → strong negative correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "910a7faa",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'plt' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[13]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Correlation matrix heatmap\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m \u001b[43mplt\u001b[49m.figure(figsize=(\u001b[32m10\u001b[39m, \u001b[32m6\u001b[39m))\n\u001b[32m      3\u001b[39m sns.heatmap(df.corr(numeric_only=\u001b[38;5;28;01mTrue\u001b[39;00m), annot=\u001b[38;5;28;01mTrue\u001b[39;00m, cmap=\u001b[33m'\u001b[39m\u001b[33mcoolwarm\u001b[39m\u001b[33m'\u001b[39m, fmt=\u001b[33m'\u001b[39m\u001b[33m.2f\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m      4\u001b[39m plt.title(\u001b[33m'\u001b[39m\u001b[33mCorrelation Heatmap of Numeric Features\u001b[39m\u001b[33m'\u001b[39m)\n",
      "\u001b[31mNameError\u001b[39m: name 'plt' is not defined"
     ]
    }
   ],
   "source": [
    "# Correlation matrix heatmap\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.heatmap(df.corr(numeric_only=True), annot=True, cmap='coolwarm', fmt='.2f')\n",
    "plt.title('Correlation Heatmap of Numeric Features')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0224a37f",
   "metadata": {},
   "source": [
    "## Exploring Feature Relationships"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3600768d",
   "metadata": {},
   "source": [
    "## Handling Missing Values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9489ec02",
   "metadata": {},
   "source": [
    "## Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40060b97",
   "metadata": {},
   "source": [
    "## Final Summary"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
